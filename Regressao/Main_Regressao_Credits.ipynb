{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68b9c1fe",
   "metadata": {},
   "source": [
    "## Importações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6da95fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_predict\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, median_absolute_error\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.svm import SVR \n",
    "from sklearn.ensemble import RandomForestRegressor "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2453413",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4407185e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/filmes_filtrados_credits.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f6f502",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e9124b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passo 1: Carregando os dados...\n",
      "Passo 2: Engenharia de Features...\n",
      "Passo 3: Preparando X e y e dividindo em treino/teste...\n",
      "Passo 4: Tratamento de Outliers (Capping)...\n",
      "Passo 5: Agrupamento de Categorias Raras (original_language)...\n",
      "Passo 6: One-Hot Encoding (original_language)...\n",
      "Passo 7: MultiLabel Binarization (genres e production_companies)...\n",
      "Passo 8: Inicializando e avaliando o modelo XGBoost...\n",
      "\n",
      "Realizando validação cruzada no conjunto de treino...\n",
      "Treinando o modelo no conjunto de treino completo...\n",
      "Realizando previsões no conjunto de teste...\n",
      "\n",
      "Métricas de Avaliação:\n",
      "                   Value\n",
      "R2_train_cv     0.416747\n",
      "MAE_train_cv    0.529386\n",
      "RMSE_train_cv   0.690032\n",
      "MedAE_train_cv  0.425330\n",
      "R2_test         0.452009\n",
      "MAE_test        0.514377\n",
      "RMSE_test       0.675054\n",
      "MedAE_test      0.411738\n",
      "\n",
      "Refatoração concluída e modelo executado.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def load_data(file_path):\n",
    "    \"\"\"Carrega o dataset a partir de um arquivo CSV.\"\"\"\n",
    "    df = pd.read_csv('../data/filmes_filtrados_credits.csv')\n",
    "    return df\n",
    "\n",
    "def feature_engineering(df):\n",
    "    \"\"\"Realiza a engenharia de features no DataFrame.\"\"\"\n",
    "    # Contagem de créditos\n",
    "    # Garante que 'credits' é uma string antes de aplicar split\n",
    "    df['credits_count'] = df['credits'].astype(str).apply(lambda x: len(x.split('-')))\n",
    "\n",
    "    # Extração de features de data\n",
    "    df['release_date'] = pd.to_datetime(df['release_date'], errors='coerce') # 'coerce' para NaN em datas inválidas\n",
    "    df['year'] = df['release_date'].dt.year\n",
    "    df['month'] = df['release_date'].dt.month\n",
    "\n",
    "    return df\n",
    "\n",
    "def handle_outliers(X_train, X_test, numeric_cols, lower_percentile=0.01, upper_percentile=0.99):\n",
    "    \"\"\"Lida com outliers aplicando capping (limitação) em colunas numéricas.\"\"\"\n",
    "    for col in numeric_cols:\n",
    "        # Verifica se a coluna existe e é numérica\n",
    "        if col in X_train.columns and pd.api.types.is_numeric_dtype(X_train[col]):\n",
    "            lower = X_train[col].quantile(lower_percentile)\n",
    "            upper = X_train[col].quantile(upper_percentile)\n",
    "            X_train[col] = X_train[col].clip(lower, upper)\n",
    "            X_test[col] = X_test[col].clip(lower, upper)\n",
    "        else:\n",
    "            print(f\"Aviso: Coluna '{col}' não encontrada ou não é numérica para tratamento de outliers. Pulando.\")\n",
    "    return X_train, X_test\n",
    "\n",
    "def group_rare_categories(series_train, series_test, min_count_threshold=50, replacement_label='Other'):\n",
    "    \"\"\"Agrupa categorias raras em uma coluna categórica.\"\"\"\n",
    "    counts = series_train.value_counts()\n",
    "    rare_categories = counts[counts < min_count_threshold].index\n",
    "    series_train_processed = series_train.replace(rare_categories, replacement_label)\n",
    "    series_test_processed = series_test.replace(rare_categories, replacement_label)\n",
    "    return series_train_processed, series_test_processed\n",
    "\n",
    "def process_multilabel_column(train_series, test_series, sep='-', top_n=12, prefix='feature'):\n",
    "    \"\"\"\n",
    "    Processa colunas multi-rótulo (e.g., gêneros, produtoras) usando MultiLabelBinarizer.\n",
    "    Filtra para os top_n mais frequentes e agrupa o restante em 'Other'.\n",
    "    \"\"\"\n",
    "    # Extrai os top_n categorias do conjunto de treino\n",
    "    exploded_train = train_series.astype(str).str.split(sep).explode().str.strip()\n",
    "    top_categories = exploded_train.value_counts().nlargest(top_n).index.tolist()\n",
    "\n",
    "    def filter_and_process(vals_series):\n",
    "        filtered_lists = []\n",
    "        for val_str in vals_series.astype(str).str.split(sep):\n",
    "            filtered_list = [v.strip() for v in val_str if v.strip() in top_categories]\n",
    "            if not filtered_list: # Se não houver top_n categorias, adicione 'Other'\n",
    "                filtered_list = ['Other']\n",
    "            filtered_lists.append(filtered_list)\n",
    "        return filtered_lists\n",
    "\n",
    "    train_filtered_lists = filter_and_process(train_series)\n",
    "    test_filtered_lists = filter_and_process(test_series)\n",
    "\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    train_enc = pd.DataFrame(\n",
    "        mlb.fit_transform(train_filtered_lists),\n",
    "        columns=[f\"{prefix}_{cls}\" for cls in mlb.classes_],\n",
    "        index=train_series.index\n",
    "    )\n",
    "    test_enc = pd.DataFrame(\n",
    "        mlb.transform(test_filtered_lists),\n",
    "        columns=[f\"{prefix}_{cls}\" for cls in mlb.classes_],\n",
    "        index=test_series.index\n",
    "    )\n",
    "    return train_enc, test_enc\n",
    "\n",
    "\n",
    "def train_and_evaluate_model(model, X_train, y_train, X_test, y_test, kf_splits=5, random_state=87):\n",
    "    \"\"\"Treina e avalia o modelo usando validação cruzada e no conjunto de teste.\"\"\"\n",
    "    kf = KFold(n_splits=kf_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "    print(\"\\nRealizando validação cruzada no conjunto de treino...\")\n",
    "    y_pred_cv_train = cross_val_predict(model, X_train, y_train, cv=kf)\n",
    "\n",
    "    print(\"Treinando o modelo no conjunto de treino completo...\")\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Realizando previsões no conjunto de teste...\")\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Métricas de avaliação\n",
    "    mse_train_cv = mean_squared_error(y_train, y_pred_cv_train)\n",
    "    rmse_train_cv = np.sqrt(mse_train_cv)\n",
    "\n",
    "    mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "    rmse_test = np.sqrt(mse_test)\n",
    "\n",
    "    metrics = {\n",
    "        'R2_train_cv': r2_score(y_train, y_pred_cv_train),\n",
    "        'MAE_train_cv': mean_absolute_error(y_train, y_pred_cv_train),\n",
    "        'RMSE_train_cv': rmse_train_cv,\n",
    "        'MedAE_train_cv': median_absolute_error(y_train, y_pred_cv_train),\n",
    "        'R2_test': r2_score(y_test, y_test_pred),\n",
    "        'MAE_test': mean_absolute_error(y_test, y_test_pred),\n",
    "        'RMSE_test': rmse_test,\n",
    "        'MedAE_test': median_absolute_error(y_test, y_test_pred),\n",
    "    }\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics, index=[0]).T\n",
    "    metrics_df.columns = ['Value']\n",
    "\n",
    "    print(\"\\nMétricas de Avaliação:\")\n",
    "    print(metrics_df)\n",
    "    return model, metrics_df\n",
    "\n",
    "\n",
    "# --- Pipeline Principal ---\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = 'filmes_filtrados_credits.csv'\n",
    "    random_seed = 87\n",
    "    test_size = 0.2\n",
    "\n",
    "    print(\"Passo 1: Carregando os dados...\")\n",
    "    df = load_data(file_path)\n",
    "\n",
    "    print(\"Passo 2: Engenharia de Features...\")\n",
    "    df = feature_engineering(df)\n",
    "\n",
    "    # Drop colunas originais que não são mais necessárias e podem causar erro\n",
    "    # Esta é a correção do erro anterior: 'credits' e 'release_date'\n",
    "    # 'genres' e 'production_companies' serão dropadas mais abaixo, após o processamento MultiLabelBinarizer\n",
    "    df = df.drop(columns=['credits', 'release_date'])\n",
    "\n",
    "\n",
    "    print(\"Passo 3: Preparando X e y e dividindo em treino/teste...\")\n",
    "    X = df.drop(columns=['vote_average'])\n",
    "    y = df['vote_average']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_seed\n",
    "    )\n",
    "\n",
    "    print(\"Passo 4: Tratamento de Outliers (Capping)...\")\n",
    "    numeric_cols_for_outliers = ['budget', 'runtime', 'credits_count', 'year', 'month']\n",
    "    X_train, X_test = handle_outliers(X_train.copy(), X_test.copy(), numeric_cols_for_outliers)\n",
    "    # Usar .copy() para evitar SettingWithCopyWarning, embora o clip já crie uma cópia em muitos casos.\n",
    "\n",
    "    print(\"Passo 5: Agrupamento de Categorias Raras (original_language)...\")\n",
    "    X_train['original_language'], X_test['original_language'] = group_rare_categories(\n",
    "        X_train['original_language'], X_test['original_language'], min_count_threshold=50\n",
    "    )\n",
    "\n",
    "    print(\"Passo 6: One-Hot Encoding (original_language)...\")\n",
    "    X_train = pd.get_dummies(X_train, columns=['original_language'], drop_first=True)\n",
    "    X_test = pd.get_dummies(X_test, columns=['original_language'], drop_first=True)\n",
    "    X_train, X_test = X_train.align(X_test, join='left', axis=1, fill_value=0) # Alinhar após get_dummies\n",
    "\n",
    "    print(\"Passo 7: MultiLabel Binarization (genres e production_companies)...\")\n",
    "    genres_train_encoded, genres_test_encoded = process_multilabel_column(\n",
    "        X_train['genres'], X_test['genres'], sep='-', top_n=12, prefix='genre'\n",
    "    )\n",
    "    X_train = X_train.drop(columns=['genres']).join(genres_train_encoded)\n",
    "    X_test = X_test.drop(columns=['genres']).join(genres_test_encoded)\n",
    "\n",
    "    prod_train_encoded, prod_test_encoded = process_multilabel_column(\n",
    "        X_train['production_companies'], X_test['production_companies'], sep='-', top_n=8, prefix='production'\n",
    "    )\n",
    "    X_train = X_train.drop(columns=['production_companies']).join(prod_train_encoded)\n",
    "    X_test = X_test.drop(columns=['production_companies']).join(prod_test_encoded)\n",
    "\n",
    "    # Alinhar novamente após MultiLabelBinarizer para garantir que as colunas correspondem\n",
    "    X_train, X_test = X_train.align(X_test, join='left', axis=1, fill_value=0)\n",
    "\n",
    "    print(\"Passo 8: Inicializando e avaliando o modelo XGBoost...\")\n",
    "    # Removendo a coluna 'title' se ela existir e não for usada, pois é do tipo 'object'\n",
    "    # Se 'title' fosse para ser usada, precisaria de um processamento de texto como TF-IDF ou embeddings\n",
    "    if 'title' in X_train.columns:\n",
    "        print(\"Aviso: 'title' detectada e será removida, pois não é numérica/categórica processada.\")\n",
    "        X_train = X_train.drop(columns=['title'])\n",
    "        X_test = X_test.drop(columns=['title'])\n",
    "\n",
    "\n",
    "    model = XGBRegressor(random_state=random_seed, n_estimators=100, verbosity=0)\n",
    "    final_model, evaluation_metrics = train_and_evaluate_model(\n",
    "        model, X_train, y_train, X_test, y_test, kf_splits=5, random_state=random_seed\n",
    "    )\n",
    "\n",
    "    print(\"\\nRefatoração concluída e modelo executado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e22c36",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7d5085d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Value\n",
      "R2     0.218136\n",
      "MAE    0.626591\n",
      "RMSE   0.806339\n",
      "MedAE  0.515157\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('../data/filmes_filtrados_credits.csv')\n",
    "# --- Pré-processamento de Dados ---\n",
    "\n",
    "# Feature: count of credits\n",
    "df['credits_count'] = df['credits'].apply(lambda x: len(x.split('-')))\n",
    "\n",
    "# Extract date features\n",
    "df['release_date'] = pd.to_datetime(df['release_date'])\n",
    "df['year'] = df['release_date'].dt.year\n",
    "df['month'] = df['release_date'].dt.month\n",
    "\n",
    "# Drop unused columns\n",
    "df = df.drop(columns=['credits', 'release_date'])\n",
    "\n",
    "# Prepare X and y\n",
    "X = df.drop(columns=['vote_average'])\n",
    "y = df['vote_average']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=87\n",
    ")\n",
    "\n",
    "# Outlier handling: cap numeric features at 1st and 99th percentiles\n",
    "numeric_cols = [ 'budget', 'runtime', 'credits_count']\n",
    "for col in numeric_cols:\n",
    "    lower = X_train[col].quantile(0.01)\n",
    "    upper = X_train[col].quantile(0.99)\n",
    "    X_train[col] = X_train[col].clip(lower, upper)\n",
    "    X_test[col] = X_test[col].clip(lower, upper)\n",
    "\n",
    "# Rare category grouping for original_language\n",
    "lang_counts = X_train['original_language'].value_counts()\n",
    "rare_langs = lang_counts[lang_counts < 50].index\n",
    "X_train['original_language'] = X_train['original_language'].replace(rare_langs, 'Other')\n",
    "X_test['original_language'] = X_test['original_language'].replace(rare_langs, 'Other')\n",
    "\n",
    "# One-hot encode original_language\n",
    "X_train = pd.get_dummies(X_train, columns=['original_language'], drop_first=True)\n",
    "X_test = pd.get_dummies(X_test, columns=['original_language'], drop_first=True)\n",
    "# Align columns\n",
    "X_train, X_test = X_train.align(X_test, join='left', axis=1, fill_value=0)\n",
    "\n",
    "# MultiLabelBinarizer for genres and production_companies\n",
    "def process_multilabel_column(train_series, test_series, sep='-', top_n=12, prefix='genre'):\n",
    "    # Extract top_n categories\n",
    "    exploded = train_series.str.split(sep).explode().str.strip()\n",
    "    top = exploded.value_counts().nlargest(top_n).index.tolist()\n",
    "\n",
    "    def filter_top(vals):\n",
    "        vals = [v.strip() for v in vals.split(sep)]\n",
    "        return [v if v in top else 'Other' for v in vals]\n",
    "\n",
    "    train_filtered = train_series.apply(filter_top)\n",
    "    test_filtered = test_series.apply(filter_top)\n",
    "\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    train_enc = pd.DataFrame(\n",
    "        mlb.fit_transform(train_filtered),\n",
    "        columns=[f\"{prefix}_{cls}\" for cls in mlb.classes_],\n",
    "        index=train_series.index\n",
    "    )\n",
    "    test_enc = pd.DataFrame(\n",
    "        mlb.transform(test_filtered),\n",
    "        columns=[f\"{prefix}_{cls}\" for cls in mlb.classes_],\n",
    "        index=test_series.index\n",
    "    )\n",
    "    return train_enc, test_enc\n",
    "\n",
    "# Genres\n",
    "genres_train, genres_test = process_multilabel_column(\n",
    "    X_train['genres'], X_test['genres'], sep='-', top_n=12, prefix='genre'\n",
    ")\n",
    "X_train = X_train.drop(columns=['genres']).join(genres_train)\n",
    "X_test = X_test.drop(columns=['genres']).join(genres_test)\n",
    "\n",
    "# Production companies\n",
    "prod_train, prod_test = process_multilabel_column(\n",
    "    X_train['production_companies'], X_test['production_companies'], sep='-', top_n=8, prefix='production'\n",
    ")\n",
    "X_train = X_train.drop(columns=['production_companies']).join(prod_train)\n",
    "X_test = X_test.drop(columns=['production_companies']).join(prod_test)\n",
    "\n",
    "# Align again after multilabel\n",
    "X_train, X_test = X_train.align(X_test, join='left', axis=1, fill_value=0)\n",
    "\n",
    "# --- Escalonamento de Features Numéricas para SVR ---\n",
    "# Identificar todas as colunas numéricas após o pré-processamento\n",
    "# Excluímos as colunas dummy (0/1) para escalonamento\n",
    "all_numeric_cols = X_train.select_dtypes(include=np.number).columns.tolist()\n",
    "# As colunas dummy (original_language_X, genre_X, production_X) não precisam ser escalonadas.\n",
    "# Vamos assumir que 'year', 'month', 'popularity', 'budget', 'runtime', 'credits_count' são as numéricas que precisam de escalonamento.\n",
    "# É uma boa prática verificar isso dinamicamente se a estrutura das colunas puder mudar.\n",
    "cols_to_scale = ['budget', 'runtime', 'credits_count', 'year', 'month']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train[cols_to_scale] = scaler.fit_transform(X_train[cols_to_scale])\n",
    "X_test[cols_to_scale] = scaler.transform(X_test[cols_to_scale])\n",
    "\n",
    "# --- Treinamento e Avaliação do Modelo SVR ---\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=87)\n",
    "model = SVR(kernel='rbf', C=1.0, epsilon=0.1) # Parâmetros iniciais para SVR\n",
    "\n",
    "# Predições de validação cruzada no conjunto de treino\n",
    "y_pred_cv_train = cross_val_predict(model, X_train, y_train, cv=kf)\n",
    "\n",
    "# Treinar o modelo no conjunto de treino completo\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predições no conjunto de teste\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# --- Métricas de Avaliação ---\n",
    "\n",
    "mse_train_cv = mean_squared_error(y_train, y_pred_cv_train)\n",
    "rmse_train_cv = np.sqrt(mse_train_cv)\n",
    "\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "\n",
    "metrics = {\n",
    "    'R2': r2_score(y_test, y_test_pred),\n",
    "    'MAE': mean_absolute_error(y_test, y_test_pred),\n",
    "    'RMSE': rmse_test,\n",
    "    'MedAE': median_absolute_error(y_test, y_test_pred),\n",
    "}\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics, index=[0]).T\n",
    "metrics_df.columns = ['Value']\n",
    "\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075c6c5a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f98a6aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Value\n",
      "R2     0.455687\n",
      "MAE    0.513751\n",
      "RMSE   0.672785\n",
      "MedAE  0.415920\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('../data/filmes_filtrados_credits.csv')\n",
    "# --- Pré-processamento de Dados ---\n",
    "\n",
    "# Feature: count of credits\n",
    "df['credits_count'] = df['credits'].apply(lambda x: len(x.split('-')))\n",
    "\n",
    "# Extract date features\n",
    "df['release_date'] = pd.to_datetime(df['release_date'])\n",
    "df['year'] = df['release_date'].dt.year\n",
    "df['month'] = df['release_date'].dt.month\n",
    "\n",
    "# Drop unused columns\n",
    "df = df.drop(columns=['credits', 'release_date'])\n",
    "\n",
    "# Prepare X and y\n",
    "X = df.drop(columns=['vote_average'])\n",
    "y = df['vote_average']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=87\n",
    ")\n",
    "\n",
    "# Outlier handling: cap numeric features at 1st and 99th percentiles\n",
    "numeric_cols = ['budget', 'runtime', 'credits_count']\n",
    "for col in numeric_cols:\n",
    "    lower = X_train[col].quantile(0.01)\n",
    "    upper = X_train[col].quantile(0.99)\n",
    "    X_train[col] = X_train[col].clip(lower, upper)\n",
    "    X_test[col] = X_test[col].clip(lower, upper)\n",
    "\n",
    "# Rare category grouping for original_language\n",
    "lang_counts = X_train['original_language'].value_counts()\n",
    "rare_langs = lang_counts[lang_counts < 50].index\n",
    "X_train['original_language'] = X_train['original_language'].replace(rare_langs, 'Other')\n",
    "X_test['original_language'] = X_test['original_language'].replace(rare_langs, 'Other')\n",
    "\n",
    "# One-hot encode original_language\n",
    "X_train = pd.get_dummies(X_train, columns=['original_language'], drop_first=True)\n",
    "X_test = pd.get_dummies(X_test, columns=['original_language'], drop_first=True)\n",
    "# Align columns\n",
    "X_train, X_test = X_train.align(X_test, join='left', axis=1, fill_value=0)\n",
    "\n",
    "# MultiLabelBinarizer for genres and production_companies\n",
    "def process_multilabel_column(train_series, test_series, sep='-', top_n=12, prefix='genre'):\n",
    "    # Extract top_n categories\n",
    "    exploded = train_series.str.split(sep).explode().str.strip()\n",
    "    top = exploded.value_counts().nlargest(top_n).index.tolist()\n",
    "\n",
    "    def filter_top(vals):\n",
    "        vals = [v.strip() for v in vals.split(sep)]\n",
    "        return [v if v in top else 'Other' for v in vals]\n",
    "\n",
    "    train_filtered = train_series.apply(filter_top)\n",
    "    test_filtered = test_series.apply(filter_top)\n",
    "\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    train_enc = pd.DataFrame(\n",
    "        mlb.fit_transform(train_filtered),\n",
    "        columns=[f\"{prefix}_{cls}\" for cls in mlb.classes_],\n",
    "        index=train_series.index\n",
    "    )\n",
    "    test_enc = pd.DataFrame(\n",
    "        mlb.transform(test_filtered),\n",
    "        columns=[f\"{prefix}_{cls}\" for cls in mlb.classes_],\n",
    "        index=test_series.index\n",
    "    )\n",
    "    return train_enc, test_enc\n",
    "\n",
    "# Genres\n",
    "genres_train, genres_test = process_multilabel_column(\n",
    "    X_train['genres'], X_test['genres'], sep='-', top_n=12, prefix='genre'\n",
    ")\n",
    "X_train = X_train.drop(columns=['genres']).join(genres_train)\n",
    "X_test = X_test.drop(columns=['genres']).join(genres_test)\n",
    "\n",
    "# Production companies\n",
    "prod_train, prod_test = process_multilabel_column(\n",
    "    X_train['production_companies'], X_test['production_companies'], sep='-', top_n=8, prefix='production'\n",
    ")\n",
    "X_train = X_train.drop(columns=['production_companies']).join(prod_train)\n",
    "X_test = X_test.drop(columns=['production_companies']).join(prod_test)\n",
    "\n",
    "# Align again after multilabel\n",
    "X_train, X_test = X_train.align(X_test, join='left', axis=1, fill_value=0)\n",
    "\n",
    "# --- Treinamento e Avaliação do Modelo Random Forest ---\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=87)\n",
    "# Parâmetros iniciais para RandomForestRegressor\n",
    "# n_estimators: número de árvores na floresta\n",
    "# random_state: para reprodutibilidade\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=87, n_jobs=-1) # n_jobs=-1 para usar todos os núcleos da CPU\n",
    "\n",
    "# Predições de validação cruzada no conjunto de treino\n",
    "y_pred_cv_train = cross_val_predict(model, X_train, y_train, cv=kf)\n",
    "\n",
    "# Treinar o modelo no conjunto de treino completo\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predições no conjunto de teste\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# --- Métricas de Avaliação ---\n",
    "\n",
    "mse_train_cv = mean_squared_error(y_train, y_pred_cv_train)\n",
    "rmse_train_cv = np.sqrt(mse_train_cv)\n",
    "\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "\n",
    "metrics = {\n",
    "    'R2': r2_score(y_test, y_test_pred),\n",
    "    'MAE': mean_absolute_error(y_test, y_test_pred),\n",
    "    'RMSE': rmse_test,\n",
    "    'MedAE': median_absolute_error(y_test, y_test_pred),\n",
    "}\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics, index=[0]).T\n",
    "metrics_df.columns = ['Value']\n",
    "\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe72b0a",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
