{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdb73808",
   "metadata": {},
   "source": [
    "## Importações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9dc044ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255ef1de",
   "metadata": {},
   "source": [
    "#### Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0a4e793a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.svm import SVR \n",
    "from sklearn.ensemble import RandomForestRegressor "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2c8dcf",
   "metadata": {},
   "source": [
    "#### Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5aaba4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, cross_val_predict\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, median_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dafa37",
   "metadata": {},
   "source": [
    "## Carregando dataset com nova coluna 'credits' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ae7a461a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    return pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a08714",
   "metadata": {},
   "source": [
    "## Dividindo os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e8c374",
   "metadata": {},
   "source": [
    "### Engenharia de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "71eb689b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    df_copy = df.copy()\n",
    "    df_copy['credits_count'] = df_copy['credits'].astype(str).apply(lambda x: len(x.split('-')))\n",
    "    df_copy['release_date'] = pd.to_datetime(df_copy['release_date'], errors='coerce')\n",
    "    df_copy['year'] = df_copy['release_date'].dt.year\n",
    "    df_copy['month'] = df_copy['release_date'].dt.month\n",
    "    df_copy = df_copy.drop(columns=['credits', 'release_date'])\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1f548a",
   "metadata": {},
   "source": [
    "### Lidando com outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0c81288b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_outliers(X_train, X_test, numeric_cols, lower_percentile=0.01, upper_percentile=0.99):\n",
    "    X_train_copy, X_test_copy = X_train.copy(), X_test.copy()\n",
    "    for col in numeric_cols:\n",
    "        if col in X_train_copy.columns and pd.api.types.is_numeric_dtype(X_train_copy[col]):\n",
    "            lower = X_train_copy[col].quantile(lower_percentile)\n",
    "            upper = X_train_copy[col].quantile(upper_percentile)\n",
    "            X_train_copy[col] = X_train_copy[col].clip(lower, upper)\n",
    "            X_test_copy[col] = X_test_copy[col].clip(lower, upper)\n",
    "    return X_train_copy, X_test_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8641a4",
   "metadata": {},
   "source": [
    "### Agrupando categorias de colunas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a9f55b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_rare_categories(series_train, series_test, min_count_threshold=50, replacement_label='Other'):\n",
    "    counts = series_train.value_counts()\n",
    "    rare_categories = counts[counts < min_count_threshold].index\n",
    "    series_train_processed = series_train.replace(rare_categories, replacement_label)\n",
    "    series_test_processed = series_test.replace(rare_categories, replacement_label)\n",
    "    test_categories_not_in_train = set(series_test_processed.unique()) - set(series_train_processed.unique())\n",
    "    if test_categories_not_in_train:\n",
    "        series_test_processed = series_test_processed.replace(list(test_categories_not_in_train), replacement_label)\n",
    "    return series_train_processed, series_test_processed\n",
    "\n",
    "def process_multilabel_column(train_series, test_series, sep='-', top_n=12, prefix='feature'):\n",
    "    exploded_train = train_series.astype(str).str.split(sep).explode().str.strip()\n",
    "    top_categories = exploded_train.value_counts().nlargest(top_n).index.tolist()\n",
    "\n",
    "    def filter_and_process(vals_series):\n",
    "        filtered_lists = []\n",
    "        for val_str in vals_series.astype(str).str.split(sep):\n",
    "            if not isinstance(val_str, list):\n",
    "                val_str = []\n",
    "            filtered_list = [v.strip() for v in val_str if v.strip() in top_categories]\n",
    "            if not filtered_list:\n",
    "                filtered_list = ['Other']\n",
    "            filtered_lists.append(filtered_list)\n",
    "        return filtered_lists\n",
    "\n",
    "    train_filtered = filter_and_process(train_series)\n",
    "    test_filtered = filter_and_process(test_series)\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    train_enc = pd.DataFrame(mlb.fit_transform(train_filtered), columns=[f\"{prefix}_{cls}\" for cls in mlb.classes_], index=train_series.index)\n",
    "    test_enc = pd.DataFrame(mlb.transform(test_filtered), columns=[f\"{prefix}_{cls}\" for cls in mlb.classes_], index=test_series.index)\n",
    "    return train_enc, test_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213ce88d",
   "metadata": {},
   "source": [
    "### Pipeline para carregar, processar e dividir os dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "13862b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(file_path, target_col='vote_average', test_size=0.2, random_state=87):\n",
    "    print(\"Iniciando preparação dos dados...\")\n",
    "\n",
    "    df = load_data(file_path)\n",
    "    df = feature_engineering(df)\n",
    "    X = df.drop(columns=[target_col])\n",
    "    y = df[target_col]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    numeric_cols_to_impute = ['budget', 'runtime', 'year', 'month']\n",
    "\n",
    "    for col in numeric_cols_to_impute:\n",
    "        if col in X_train.columns:\n",
    "            median_val = X_train[col].median()\n",
    "            X_train[col] = X_train[col].fillna(median_val)\n",
    "            X_test[col] = X_test[col].fillna(median_val) \n",
    "\n",
    "    numeric_cols = ['budget', 'runtime', 'credits_count', 'year', 'month']\n",
    "    X_train, X_test = handle_outliers(X_train, X_test, numeric_cols)\n",
    "    \n",
    "    X_train['original_language'], X_test['original_language'] = group_rare_categories(\n",
    "        X_train['original_language'], X_test['original_language'], min_count_threshold=50\n",
    "    )\n",
    "    X_train = pd.get_dummies(X_train, columns=['original_language'], drop_first=True)\n",
    "    X_test = pd.get_dummies(X_test, columns=['original_language'], drop_first=True)\n",
    "    \n",
    "    genres_train_enc, genres_test_enc = process_multilabel_column(X_train['genres'], X_test['genres'], sep='-', top_n=12, prefix='genre')\n",
    "    X_train = X_train.drop(columns=['genres']).join(genres_train_enc)\n",
    "    X_test = X_test.drop(columns=['genres']).join(genres_test_enc)\n",
    "    \n",
    "    prod_train_enc, prod_test_enc = process_multilabel_column(X_train['production_companies'], X_test['production_companies'], sep='-', top_n=8, prefix='prod')\n",
    "    X_train = X_train.drop(columns=['production_companies']).join(prod_train_enc)\n",
    "    X_test = X_test.drop(columns=['production_companies']).join(prod_test_enc)\n",
    "    \n",
    "    if 'title' in X_train.columns:\n",
    "        X_train = X_train.drop(columns=['title'])\n",
    "        X_test = X_test.drop(columns=['title'])\n",
    "        \n",
    "    X_train, X_test = X_train.align(X_test, join='left', axis=1, fill_value=0)\n",
    "    \n",
    "    print(\"Preparação dos dados concluída.\")\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64b70e6",
   "metadata": {},
   "source": [
    "## Preparação dos dados para Treinamento e Avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e721fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando preparação dos dados...\n",
      "Preparação dos dados concluída.\n"
     ]
    }
   ],
   "source": [
    "FILE_PATH = '../data/filmes_filtrados_credits.csv'\n",
    "RANDOM_SEED = 87\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "X_train, X_test, y_train, y_test = prepare_data(\n",
    "    file_path=FILE_PATH, \n",
    "    target_col='vote_average', \n",
    "    test_size=TEST_SIZE, \n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, index=X_train.index, columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, index=X_test.index, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee520192",
   "metadata": {},
   "source": [
    "## Definição dos modelos\n",
    "- Modelo RandomForest\n",
    "- Modelo XGBRegressor\n",
    "- Modelo SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7dd7476c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"RandomForest\": RandomForestRegressor(\n",
    "    n_estimators=200, \n",
    "    max_depth=10,\n",
    "    min_samples_leaf=4,\n",
    "    random_state=RANDOM_SEED,\n",
    "    n_jobs=-1 \n",
    "    ),\n",
    "    \"XGBoost\": XGBRegressor(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=5,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=RANDOM_SEED,\n",
    "    n_jobs=-1,\n",
    "    verbosity=0\n",
    "    ),\n",
    "    \"SVR\": SVR(\n",
    "    kernel='rbf', \n",
    "    C=1.0,      \n",
    "    gamma='scale'\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e06b14",
   "metadata": {},
   "source": [
    "## Treinamento e Avaliação dos Modelos de  Regressão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "894114b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==================================================\n",
      "      Métricas de Avaliação Consolidadas      \n",
      "==================================================\n",
      "                    R2       MAE      RMSE     MedAE\n",
      "RandomForest  0.399492  0.969570  1.511209  0.592048\n",
      "XGBoost       0.407013  0.951707  1.501715  0.561051\n",
      "SVR           0.144854  1.089977  1.803372  0.595216\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "all_metrics = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    if name == \"SVR\":\n",
    "        X_train_fit, X_test_fit = X_train_scaled, X_test_scaled\n",
    "    else:\n",
    "        X_train_fit, X_test_fit = X_train, X_test\n",
    "\n",
    "    y_pred_cv_train = cross_val_predict(model, X_train_fit, y_train, cv=kf, n_jobs=-1)\n",
    "\n",
    "    model.fit(X_train_fit, y_train)\n",
    "    \n",
    "    y_test_pred = model.predict(X_test_fit)\n",
    "\n",
    "    metrics = {\n",
    "        'R2': r2_score(y_test, y_test_pred),\n",
    "        'MAE': mean_absolute_error(y_test, y_test_pred),\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_test, y_test_pred)),\n",
    "        'MedAE': median_absolute_error(y_test, y_test_pred)\n",
    "    }\n",
    "    all_metrics[name] = metrics\n",
    "\n",
    "print(\"\\n\\n==================================================\")\n",
    "print(\"      Métricas de Avaliação Consolidadas      \")\n",
    "print(\"==================================================\")\n",
    "\n",
    "metrics_df = pd.DataFrame(all_metrics).T\n",
    "print(metrics_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
