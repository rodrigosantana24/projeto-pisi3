{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "928ebbbb",
   "metadata": {},
   "source": [
    "# Importações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd81e6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scikit-learn pandas numpy matplotlib xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b338c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pré-processamento e pipelines\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# Modelos de ML\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Validação e busca de hiperparâmetros\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform, loguniform\n",
    "\n",
    "# Métricas\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, median_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b6ee80",
   "metadata": {},
   "source": [
    "# Carregando dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e68a0c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o dataset\n",
    "df = pd.read_csv('filmes_gabriel.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5280c649",
   "metadata": {},
   "source": [
    "# Dividindo os dados\n",
    "- X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61874500",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = df[['popularity', 'budget', 'runtime']].columns\n",
    "categorical_col = ['original_language']\n",
    "date_column = 'release_date'\n",
    "\n",
    "X = df.drop(columns=['vote_average'])\n",
    "y = df['vote_average']\n",
    "\n",
    "# Dividindo o dataset em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=87)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbf3971",
   "metadata": {},
   "source": [
    "# Transformadores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff390a0e",
   "metadata": {},
   "source": [
    "## Colunas: Generos Cinematográficos e Produtora\n",
    "Aplicando MultiLabelBinarize com limites de 12 e 10, respectivamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16fce408",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_multilabel_column(train_series, test_series, sep='-', top_n=20, outros=True, prefix=''):\n",
    "    # Extrair top N do treino\n",
    "    exploded = train_series.str.split(sep).explode().str.strip()\n",
    "    top = exploded.value_counts().nlargest(top_n).index\n",
    "\n",
    "    def filter_top(vals):\n",
    "        vals = [v.strip() for v in vals.split(sep)]\n",
    "        if outros:\n",
    "            return [v if v in top else 'Outros' for v in vals]\n",
    "        else:\n",
    "            return [v for v in vals if v in top]\n",
    "\n",
    "    # Aplicar transformação\n",
    "    train_processed = train_series.apply(filter_top)\n",
    "    test_processed = test_series.apply(filter_top)\n",
    "\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    train_encoded = pd.DataFrame(\n",
    "        mlb.fit_transform(train_processed),\n",
    "        columns=[f'{prefix}_{cls}' for cls in mlb.classes_],\n",
    "        index=train_series.index\n",
    "    )\n",
    "    test_encoded = pd.DataFrame(\n",
    "        mlb.transform(test_processed),\n",
    "        columns=[f'{prefix}_{cls}' for cls in mlb.classes_],\n",
    "        index=test_series.index\n",
    "    )\n",
    "\n",
    "    return train_encoded, test_encoded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884354ce",
   "metadata": {},
   "source": [
    "### Generos cinematográficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ca4948b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genres\n",
      "Drama              3380\n",
      "Comedy             2486\n",
      "Thriller           1974\n",
      "Action             1893\n",
      "Romance            1253\n",
      "Adventure          1196\n",
      "Horror             1174\n",
      "Crime              1161\n",
      "Science Fiction     864\n",
      "Fantasy             691\n",
      "Family              683\n",
      "Mystery             666\n",
      "History             381\n",
      "Animation           364\n",
      "War                 303\n",
      "Music               220\n",
      "Western             129\n",
      "Documentary          90\n",
      "TV Movie             59\n",
      "Name: count, dtype: int64\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "teste = X_train['genres'].apply(lambda x: x.split('-')).copy()\n",
    "teste = teste.explode().reset_index(drop=True)\n",
    "genre_counts = teste.value_counts() # Apply value_counts directly to the Series\n",
    "print(genre_counts)\n",
    "print(len(genre_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43dabd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_train, genres_test = process_multilabel_column(\n",
    "    X_train['genres'], X_test['genres'], sep='-', top_n=12, outros=True, prefix='genre'\n",
    ")\n",
    "\n",
    "# Substituir a coluna original\n",
    "X_train = X_train.drop(columns='genres').join(genres_train)\n",
    "X_test = X_test.drop(columns='genres').join(genres_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35013b6a",
   "metadata": {},
   "source": [
    "### Produtora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c97f164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "production_companies\n",
      "Universal Pictures                        444\n",
      "Warner Bros. Pictures                     441\n",
      "Columbia Pictures                         343\n",
      "Paramount                                 333\n",
      "20th Century Fox                          315\n",
      "                                         ... \n",
      "October Pictures                            1\n",
      "Eidos Films                                 1\n",
      "Samuelson Productions                       1\n",
      "Gorai / Samuelson Productions               1\n",
      "Arlington Road Productions Corporation      1\n",
      "Name: count, Length: 9045, dtype: int64\n",
      "9045\n"
     ]
    }
   ],
   "source": [
    "teste = X_train['production_companies'].apply(lambda x: x.split('-')).copy()\n",
    "teste = teste.explode().reset_index(drop=True)\n",
    "production_counts = teste.value_counts() # Apply value_counts directly to the Series\n",
    "print(production_counts)\n",
    "print(len(production_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae0bd0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "production_train, production_test = process_multilabel_column(\n",
    "    X_train['production_companies'], X_test['production_companies'], sep='-', top_n=10, outros=True, prefix='production'\n",
    ")\n",
    "\n",
    "# Substituir a coluna original\n",
    "X_train = X_train.drop(columns='production_companies').join(production_train)\n",
    "X_test = X_test.drop(columns='production_companies').join(production_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b923114",
   "metadata": {},
   "source": [
    "## Colunas de data\n",
    "Transformer: Data para ano/mês"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a635f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DateFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, date_column):\n",
    "        self.date_column = date_column\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X[self.date_column] = pd.to_datetime(X[self.date_column], errors='coerce')\n",
    "        X['year'] = X[self.date_column].dt.year\n",
    "        X['month'] = X[self.date_column].dt.month\n",
    "        return X.drop(columns=[self.date_column])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd04912",
   "metadata": {},
   "source": [
    "## Outliers\n",
    "- CapTransformer: Cap\n",
    "- LogCapTransformer: Cap + Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "259834ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "        self.bounds_ = {}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        for col in self.columns:\n",
    "            Q1 = X[col].quantile(0.25)\n",
    "            Q3 = X[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower = Q1 - 1.5 * IQR\n",
    "            upper = Q3 + 1.5 * IQR\n",
    "            self.bounds_[col] = (lower, upper)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for col in self.columns:\n",
    "            lower, upper = self.bounds_[col]\n",
    "            X[col] = X[col].clip(lower, upper)\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d768ea6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogCapTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "        self.bounds_ = {}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        for col in self.columns:\n",
    "            Q1 = X[col].quantile(0.25)\n",
    "            Q3 = X[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower = Q1 - 1.5 * IQR\n",
    "            upper = Q3 + 1.5 * IQR\n",
    "            self.bounds_[col] = (lower, upper)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for col in self.columns:\n",
    "            lower, upper = self.bounds_[col]\n",
    "            X[col] = X[col].clip(lower, upper)\n",
    "            X[col] = np.log1p(X[col])\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f012cf",
   "metadata": {},
   "source": [
    "# Identificando outliers (graficos-modelo-se quiser)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7a5e2d",
   "metadata": {},
   "source": [
    "numeric_cols = df[['popularity', 'budget', 'runtime']].columns\n",
    "\n",
    "for col in numeric_cols:\n",
    "    plt.figure(figsize=(8, 1))\n",
    "    plt.boxplot(df[col], vert=False)\n",
    "    plt.title(f'Boxplot de {col}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7199ecea",
   "metadata": {},
   "source": [
    "### Tratamento com Cap nos outliers\n",
    " - Função para aplicar o \"cap\" nos outliers usando o método do IQR (Interquartile Range).\n",
    " - O cap limita os valores extremos (outliers) ao valor máximo permitido pelo intervalo interquartil,\n",
    " - reduzindo o impacto desses valores sem removê-los do dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d385da",
   "metadata": {},
   "source": [
    "\n",
    "def log_transform(df, columns):\n",
    "    df = df.copy()\n",
    "    for col in columns:\n",
    "        df[col] = np.log1p(df[col])\n",
    "    return df\n",
    "\n",
    "\n",
    "def cap_outliers_iqr(df, columns):\n",
    "    df = df.copy()\n",
    "    bounds = {}  \n",
    "    for col in columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower = Q1 - 1.5 * IQR\n",
    "        upper = Q3 + 1.5 * IQR\n",
    "        df[col] = df[col].clip(lower, upper)\n",
    "        bounds[col] = (lower, upper)\n",
    "    return df, bounds\n",
    "\n",
    "\n",
    "def apply_outlier_bounds(df, bounds):\n",
    "    df = df.copy()\n",
    "    for col, (lower, upper) in bounds.items():\n",
    "        df[col] = df[col].clip(lower, upper)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1811d40e",
   "metadata": {},
   "source": [
    "X_train, bounds = cap_outliers_iqr(X_train, numeric_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663126dc",
   "metadata": {},
   "source": [
    "X_test = apply_outlier_bounds(X_test, bounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af851c90",
   "metadata": {},
   "source": [
    "X_train = log_transform(X_train, numeric_cols)\n",
    "X_test = log_transform(X_test, numeric_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d250f8d9",
   "metadata": {},
   "source": [
    "def log_transform(df, columns):\n",
    "    for col in columns:\n",
    "        # Adiciona 1 para evitar log(0)\n",
    "        df[col] = np.log1p(df[col])\n",
    "    return df\n",
    "\n",
    "def cap_outliers_iqr(df, columns):\n",
    "    for col in columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower = Q1 - 1.5 * IQR\n",
    "        upper = Q3 + 1.5 * IQR\n",
    "        df[col] = df[col].clip(lower, upper)\n",
    "    return df\n",
    "\n",
    "df = log_transform(df, numeric_cols)\n",
    "df = cap_outliers_iqr(df, numeric_cols)\n",
    "\n",
    "for col in numeric_cols:\n",
    "    plt.figure(figsize=(8, 1))\n",
    "    plt.boxplot(df[col], vert=False)\n",
    "    plt.title(f'Boxplot de {col} (log + cap_outliers_iqr)')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c90794",
   "metadata": {},
   "source": [
    "# Treinamento\n",
    "- Modelo XGBRegressor\n",
    "- Modelo SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3157e350",
   "metadata": {},
   "source": [
    "### Definindo Kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ff9ed3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo o KFold para o cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=87)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7321a7",
   "metadata": {},
   "source": [
    "### XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d122d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Melhores parâmetros: {'regressor__colsample_bytree': np.float64(0.8696231377727208), 'regressor__learning_rate': np.float64(0.05992056035524427), 'regressor__max_depth': 5, 'regressor__n_estimators': 241, 'regressor__subsample': np.float64(0.8173221947525602)}\n",
      "Melhor R² (validação cruzada): 0.48837201095390803\n"
     ]
    }
   ],
   "source": [
    "# Cap de outliers + padronização\n",
    "num_pipeline = Pipeline([\n",
    "    ('cap', CapTransformer(columns=numerical_cols)),\n",
    "    ('scale', StandardScaler())\n",
    "])\n",
    "\n",
    "# OneHot para variáveis categóricas\n",
    "cat_pipeline = Pipeline([\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "# Pré-processador geral\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipeline, numerical_cols),\n",
    "    ('cat', cat_pipeline, categorical_col)\n",
    "], remainder='passthrough')  # passa as colunas de ano/mês e binarizadas\n",
    "\n",
    "\n",
    "# Pipeline Completo\n",
    "pipeline = Pipeline([\n",
    "    ('date', DateFeatureExtractor(date_column=date_column)),  # extrai year e month\n",
    "    ('preprocess', preprocessor),\n",
    "    ('regressor', XGBRegressor(objective='reg:squarederror', random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "# RandomizedSearch\n",
    "param_dist = {\n",
    "    'regressor__n_estimators': randint(100, 300),\n",
    "    'regressor__max_depth': randint(3, 10),\n",
    "    'regressor__learning_rate': uniform(0.01, 0.3),\n",
    "    'regressor__subsample': uniform(0.7, 0.3),\n",
    "    'regressor__colsample_bytree': uniform(0.7, 0.3),\n",
    "}\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=87)\n",
    "\n",
    "XGBRegressor_rand = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,\n",
    "    cv=kf,\n",
    "    scoring='r2',\n",
    "    random_state=87,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Treinamento e resultado\n",
    "XGBRegressor_rand.fit(X_train, y_train)\n",
    "\n",
    "print(\"Melhores parâmetros:\", XGBRegressor_rand.best_params_)\n",
    "print(\"Melhor R² (validação cruzada):\", XGBRegressor_rand.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf98090",
   "metadata": {},
   "source": [
    "### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7a90fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Melhores parâmetros: {'regressor__C': np.float64(4.217516020234043), 'regressor__epsilon': np.float64(0.29647041307396826), 'regressor__gamma': 'auto', 'regressor__kernel': 'rbf'}\n",
      "Melhor R² (validação cruzada): 0.45791552953965875\n"
     ]
    }
   ],
   "source": [
    "# Pipeline para numéricas com cap e padronização\n",
    "num_pipeline = Pipeline([\n",
    "    ('cap', CapTransformer(columns=numerical_cols)),\n",
    "    ('scale', StandardScaler())\n",
    "])\n",
    "\n",
    "# Pipeline para categóricas com OneHot\n",
    "cat_pipeline = Pipeline([\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "# ColumnTransformer para combinar tudo\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipeline, numerical_cols),\n",
    "    ('cat', cat_pipeline, categorical_col)\n",
    "], remainder='passthrough')  # mantém as colunas como 'year', 'month', e as multilabel binarizadas\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('date', DateFeatureExtractor(date_column=date_column)),  # extrai 'year' e 'month'\n",
    "    ('preprocess', preprocessor),\n",
    "    ('regressor', SVR())\n",
    "])\n",
    "\n",
    "param_dist = {\n",
    "    'regressor__kernel': ['rbf', 'linear'],\n",
    "    'regressor__C': loguniform(1e-2, 1e2),\n",
    "    'regressor__epsilon': uniform(0.01, 0.3),\n",
    "    'regressor__gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "\n",
    "svm_rand = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,  # aumentei para melhorar a busca, mas pode manter em 10 se quiser rapidez\n",
    "    cv=kf,\n",
    "    scoring='r2',\n",
    "    random_state=87,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "svm_rand.fit(X_train, y_train)\n",
    "\n",
    "print(\"Melhores parâmetros:\", svm_rand.best_params_)\n",
    "print(\"Melhor R² (validação cruzada):\", svm_rand.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b239bf00",
   "metadata": {},
   "source": [
    "# Avaliação dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4871d859",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model_name, model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    return {\n",
    "        'Modelo': model_name,\n",
    "        'R²': r2_score(y_test, y_pred),\n",
    "        'MAE': mean_absolute_error(y_test, y_pred),\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_test, y_pred)),\n",
    "        'MedAE': median_absolute_error(y_test, y_pred)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a26f8ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Modelo        R²       MAE      RMSE     MedAE\n",
      "0  XGBRegressor  0.482426  0.491358  0.644614  0.395054\n",
      "1           SVR  0.441534  0.504149  0.669594  0.389334\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "results.append(evaluate_model(\"XGBRegressor\", XGBRegressor_rand.best_estimator_, X_test, y_test))\n",
    "results.append(evaluate_model(\"SVR\", svm_rand.best_estimator_, X_test, y_test))\n",
    "\n",
    "import pandas as pd\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
