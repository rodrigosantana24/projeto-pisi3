{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "395e1c82",
   "metadata": {},
   "source": [
    "# Importações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "96524b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scikit-learn pandas numpy matplotlib xgboost smogn imbalanced-learn scipy\n",
    "\n",
    "#Caso dê algum erro nas importacoes rodar os comandos abaixo:\n",
    "#!pip uninstall -y scikit-learn imbalanced-learn scipy\n",
    "#!pip install scikit-learn==1.3.2 scipy==1.11.4 imbalanced-learn==0.11.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aae75188",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MultiLabelBinarizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split, KFold, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.stats import randint, uniform, loguniform\n",
    "\n",
    "import smogn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTEENN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e612b12a",
   "metadata": {},
   "source": [
    "# Carregando dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "59710284",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('filmes_luan.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a8550b",
   "metadata": {},
   "source": [
    "# Extraindo data para ano e mês"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "94708dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DateFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, date_column):\n",
    "        self.date_column = date_column\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X[self.date_column] = pd.to_datetime(X[self.date_column], errors='coerce')\n",
    "        X['year'] = X[self.date_column].dt.year\n",
    "        X['month'] = X[self.date_column].dt.month\n",
    "        return X.drop(columns=[self.date_column])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0a5309",
   "metadata": {},
   "source": [
    "### Tratamento com CAP + LOG nos outliers\n",
    " - Substitui outliers extremos pelos percentis limite.\n",
    " - reduz o impacto de valores extremos sem truncar bruscamente como o CAP faz.\n",
    " - reduzindo o impacto desses valores sem removê-los do dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0488db95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogCapTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "        self.bounds_ = {}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        for col in self.columns:\n",
    "            Q1 = X[col].quantile(0.25)\n",
    "            Q3 = X[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            self.bounds_[col] = (Q1 - 1.5 * IQR, Q3 + 1.5 * IQR)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for col in self.columns:\n",
    "            lower, upper = self.bounds_[col]\n",
    "            X[col] = X[col].clip(lower, upper)\n",
    "            X[col] = np.log1p(X[col])\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7a4372",
   "metadata": {},
   "source": [
    "## Função para processar colunas multilabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "66fe1a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_multilabel_column(train_series, test_series, sep='-', top_n=20, outros=True, prefix=''):\n",
    "    exploded = train_series.str.split(sep).explode().str.strip()\n",
    "    top = exploded.value_counts().nlargest(top_n).index\n",
    "\n",
    "    def filter_top(vals):\n",
    "        vals = [v.strip() for v in vals.split(sep)]\n",
    "        return [v if v in top else 'Outros' for v in vals] if outros else [v for v in vals if v in top]\n",
    "\n",
    "    train_processed = train_series.apply(filter_top)\n",
    "    test_processed = test_series.apply(filter_top)\n",
    "\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    train_encoded = pd.DataFrame(\n",
    "        mlb.fit_transform(train_processed),\n",
    "        columns=[f'{prefix}_{cls}' for cls in mlb.classes_],\n",
    "        index=train_series.index\n",
    "    )\n",
    "    test_encoded = pd.DataFrame(\n",
    "        mlb.transform(test_processed),\n",
    "        columns=[f'{prefix}_{cls}' for cls in mlb.classes_],\n",
    "        index=test_series.index\n",
    "    )\n",
    "    return train_encoded, test_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfeb4217",
   "metadata": {},
   "source": [
    "## DIVISÃO E TRANSFORMAÇÃO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cca63d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['vote_average'])\n",
    "y = df['vote_average']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=87)\n",
    "\n",
    "genres_train, genres_test = process_multilabel_column(\n",
    "    X_train['genres'], X_test['genres'], sep='-', top_n=12, outros=True, prefix='genre'\n",
    ")\n",
    "X_train = X_train.drop(columns='genres').join(genres_train)\n",
    "X_test = X_test.drop(columns='genres').join(genres_test)\n",
    "\n",
    "production_train, production_test = process_multilabel_column(\n",
    "    X_train['production_companies'], X_test['production_companies'], sep='-', top_n=10, outros=True, prefix='production'\n",
    ")\n",
    "X_train = X_train.drop(columns='production_companies').join(production_train)\n",
    "X_test = X_test.drop(columns='production_companies').join(production_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5db7c8",
   "metadata": {},
   "source": [
    "# Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3ec3b0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = ['popularity', 'budget', 'runtime']\n",
    "categorical_col = ['original_language']\n",
    "date_column = 'release_date'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab27cef",
   "metadata": {},
   "source": [
    "### Pré-processamento completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b9d01324",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline([\n",
    "    ('logcap', LogCapTransformer(columns=numerical_cols)),\n",
    "    ('scale', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipeline, numerical_cols),\n",
    "    ('cat', cat_pipeline, categorical_col)\n",
    "], remainder='passthrough')\n",
    "\n",
    "full_pipeline = Pipeline([\n",
    "    ('date', DateFeatureExtractor(date_column=date_column)),\n",
    "    ('preprocess', preprocessor)\n",
    "])\n",
    "\n",
    "X_train_transf = full_pipeline.fit_transform(X_train)\n",
    "X_test_transf = full_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1785d76e",
   "metadata": {},
   "source": [
    "### Aplicando SMOGN, SMOTE e SMOTEENN\n",
    "- Balanceamento para usar SMOTE e SMOTEENN na regressão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8a66712f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dist_matrix: 100%|##########| 695/695 [01:46<00:00,  6.50it/s]\n",
      "synth_matrix: 100%|##########| 695/695 [00:01<00:00, 371.02it/s]\n",
      "r_index: 100%|##########| 386/386 [00:00<00:00, 733.91it/s]\n",
      "dist_matrix: 100%|##########| 587/587 [01:33<00:00,  6.29it/s]\n",
      "synth_matrix: 100%|##########| 587/587 [00:02<00:00, 219.79it/s]\n",
      "r_index: 100%|##########| 123/123 [00:00<00:00, 643.31it/s]\n"
     ]
    }
   ],
   "source": [
    "# Transformar alvo contínuo em bins\n",
    "y_train_binned = pd.qcut(y_train, q=5, labels=False)\n",
    "\n",
    "# SMOTE\n",
    "X_smote, y_smote = SMOTE(random_state=42).fit_resample(X_train_transf, y_train_binned)\n",
    "\n",
    "# SMOTEENN\n",
    "X_smoteenn, y_smoteenn = SMOTEENN(random_state=42).fit_resample(X_train_transf, y_train_binned)\n",
    "\n",
    "# SMOGN\n",
    "X_smogn_df = pd.DataFrame(X_train_transf)\n",
    "X_smogn_df['vote_average'] = y_train.values\n",
    "X_smogn = smogn.smoter(data=X_smogn_df, y='vote_average', k=3, samp_method='balance')\n",
    "y_smogn = X_smogn['vote_average']\n",
    "X_smogn = X_smogn.drop(columns=['vote_average'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b78457c",
   "metadata": {},
   "source": [
    "# Treinamento dos Modelos\n",
    "- Modelo XGBRegressor\n",
    "- Modelo SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c00c529",
   "metadata": {},
   "source": [
    "### XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a4e14a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "Melhores parâmetros XGB: {'regressor__colsample_bytree': 0.755226088407728, 'regressor__learning_rate': 0.07272737227112255, 'regressor__max_depth': 5, 'regressor__n_estimators': 170, 'regressor__subsample': 0.8300538566031057}\n",
      "Melhor R² (XGB): 0.49198798633056706\n"
     ]
    }
   ],
   "source": [
    "xgb_pipeline = Pipeline([\n",
    "    ('regressor', XGBRegressor(objective='reg:squarederror', random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "param_dist_xgb = {\n",
    "    'regressor__n_estimators': randint(100, 300),\n",
    "    'regressor__max_depth': randint(3, 10),\n",
    "    'regressor__learning_rate': uniform(0.01, 0.3),\n",
    "    'regressor__subsample': uniform(0.7, 0.3),\n",
    "    'regressor__colsample_bytree': uniform(0.7, 0.3),\n",
    "}\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=87)\n",
    "\n",
    "xgb_rand = RandomizedSearchCV(\n",
    "    estimator=xgb_pipeline,\n",
    "    param_distributions=param_dist_xgb,\n",
    "    n_iter=60,\n",
    "    cv=kf,\n",
    "    scoring='r2',\n",
    "    random_state=87,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "xgb_rand.fit(X_train_transf, y_train)\n",
    "print(\"Melhores parâmetros XGB:\", xgb_rand.best_params_)\n",
    "print(\"Melhor R² (XGB):\", xgb_rand.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f303d7c0",
   "metadata": {},
   "source": [
    "### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bc4b7744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Melhores parâmetros SVR: {'regressor__C': 0.017073967431528128, 'regressor__epsilon': 0.26985284373248053, 'regressor__gamma': 'auto', 'regressor__kernel': 'linear'}\n",
      "Melhor R² (SVR): 0.4270260012299543\n"
     ]
    }
   ],
   "source": [
    "svr_pipeline = Pipeline([\n",
    "    ('regressor', SVR())\n",
    "])\n",
    "\n",
    "param_dist_svr = {\n",
    "    'regressor__kernel': ['rbf', 'linear'],\n",
    "    'regressor__C': loguniform(1e-2, 1e2),\n",
    "    'regressor__epsilon': uniform(0.01, 0.3),\n",
    "    'regressor__gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "svm_rand = RandomizedSearchCV(\n",
    "    estimator=svr_pipeline,\n",
    "    param_distributions=param_dist_svr,\n",
    "    n_iter=10,\n",
    "    cv=kf,\n",
    "    scoring='r2',\n",
    "    random_state=42,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "svm_rand.fit(X_train_transf, y_train)\n",
    "print(\"Melhores parâmetros SVR:\", svm_rand.best_params_)\n",
    "print(\"Melhor R² (SVR):\", svm_rand.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5cef16",
   "metadata": {},
   "source": [
    "# Avaliação final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a4b6bcff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Modelo        MSE      RMSE         R²\n",
      "2     XGBRegressor + SMOGN   0.467544  0.683772   0.417634\n",
      "5              SVR + SMOGN   0.625158  0.790670   0.221312\n",
      "1  XGBRegressor + SMOTEENN  19.161391  4.377373 -22.867152\n",
      "4           SVR + SMOTEENN  19.654185  4.433304 -23.480970\n",
      "3              SVR + SMOTE  19.829205  4.453000 -23.698972\n",
      "0     XGBRegressor + SMOTE  19.904447  4.461440 -23.792692\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "def strip_regressor_prefix(params):\n",
    "    return {k.replace('regressor__', ''): v for k, v in params.items()}\n",
    "\n",
    "xgb_best_params = strip_regressor_prefix(xgb_rand.best_params_)\n",
    "svr_best_params = strip_regressor_prefix(svm_rand.best_params_)\n",
    "\n",
    "modelos_bal = {\n",
    "    'XGBRegressor + SMOTE': XGBRegressor(**xgb_best_params, objective='reg:squarederror', n_jobs=-1),\n",
    "    'XGBRegressor + SMOTEENN': XGBRegressor(**xgb_best_params, objective='reg:squarederror', n_jobs=-1),\n",
    "    'XGBRegressor + SMOGN': XGBRegressor(**xgb_best_params, objective='reg:squarederror', n_jobs=-1),\n",
    "    'SVR + SMOTE': SVR(**svr_best_params),\n",
    "    'SVR + SMOTEENN': SVR(**svr_best_params),\n",
    "    'SVR + SMOGN': SVR(**svr_best_params),\n",
    "}\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for nome, modelo in modelos_bal.items():\n",
    "    if 'SMOGN' in nome:\n",
    "        X_bal, y_bal = X_smogn, y_smogn\n",
    "    elif 'SMOTEENN' in nome:\n",
    "        X_bal, y_bal = X_smoteenn, y_smoteenn\n",
    "    else:\n",
    "        X_bal, y_bal = X_smote, y_smote\n",
    "\n",
    "    modelo.fit(X_bal, y_bal)\n",
    "    y_pred = modelo.predict(X_test_transf)\n",
    "\n",
    "    resultados.append({\n",
    "        'Modelo': nome,\n",
    "        'MSE': mean_squared_error(y_test, y_pred),\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_test, y_pred)),\n",
    "        'R²': r2_score(y_test, y_pred)\n",
    "    })\n",
    "\n",
    "resultados_df = pd.DataFrame(resultados)\n",
    "print(resultados_df.sort_values(by='R²', ascending=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
