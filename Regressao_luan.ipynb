{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "395e1c82",
   "metadata": {},
   "source": [
    "# Importações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96524b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scikit-learn pandas numpy matplotlib xgboost smogn imbalanced-learn scipy\n",
    "\n",
    "#Caso dê algum erro nas importacoes rodar os comandos abaixo:\n",
    "#!pip uninstall -y scikit-learn imbalanced-learn scipy\n",
    "#!pip install scikit-learn==1.3.2 scipy==1.11.4 imbalanced-learn==0.11.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aae75188",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MultiLabelBinarizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split, KFold, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.stats import randint, uniform, loguniform\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "import smogn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTEENN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e612b12a",
   "metadata": {},
   "source": [
    "# Carregando dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59710284",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('filmes_luan.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a8550b",
   "metadata": {},
   "source": [
    "# Extraindo data para ano e mês"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94708dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DateFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, date_column):\n",
    "        self.date_column = date_column\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X[self.date_column] = pd.to_datetime(X[self.date_column], errors='coerce')\n",
    "        X['year'] = X[self.date_column].dt.year\n",
    "        X['month'] = X[self.date_column].dt.month\n",
    "        return X.drop(columns=[self.date_column])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0a5309",
   "metadata": {},
   "source": [
    "### Tratamento com CAP + LOG nos outliers\n",
    " - Substitui outliers extremos pelos percentis limite.\n",
    " - reduz o impacto de valores extremos sem truncar bruscamente como o CAP faz.\n",
    " - reduzindo o impacto desses valores sem removê-los do dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0488db95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogCapTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "        self.bounds_ = {}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        for col in self.columns:\n",
    "            Q1 = X[col].quantile(0.25)\n",
    "            Q3 = X[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            self.bounds_[col] = (Q1 - 1.5 * IQR, Q3 + 1.5 * IQR)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for col in self.columns:\n",
    "            lower, upper = self.bounds_[col]\n",
    "            X[col] = X[col].clip(lower, upper)\n",
    "            X[col] = np.log1p(X[col])\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c2a41b",
   "metadata": {},
   "source": [
    "## Alternativas para tratamento de outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7efbefaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "num_pipeline_std = Pipeline([\n",
    "    ('scale', StandardScaler())\n",
    "])\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "num_pipeline_robust = Pipeline([\n",
    "    ('scale', RobustScaler())\n",
    "])\n",
    "\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "num_pipeline_yeojohnson = Pipeline([\n",
    "    ('power', PowerTransformer(method='yeo-johnson')),\n",
    "    ('scale', StandardScaler())\n",
    "])\n",
    "\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "num_pipeline_quantile = Pipeline([\n",
    "    ('quantile', QuantileTransformer(output_distribution='normal')),\n",
    "    ('scale', StandardScaler())\n",
    "])\n",
    "\n",
    "class CapTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "        self.bounds_ = {}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        for col in self.columns:\n",
    "            Q1 = X[col].quantile(0.25)\n",
    "            Q3 = X[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            self.bounds_[col] = (Q1 - 1.5 * IQR, Q3 + 1.5 * IQR)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for col in self.columns:\n",
    "            lower, upper = self.bounds_[col]\n",
    "            X[col] = X[col].clip(lower, upper)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7a4372",
   "metadata": {},
   "source": [
    "## Função para processar colunas multilabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66fe1a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_multilabel_column(train_series, test_series, sep='-', top_n=20, outros=True, prefix=''):\n",
    "    exploded = train_series.str.split(sep).explode().str.strip()\n",
    "    top = exploded.value_counts().nlargest(top_n).index\n",
    "\n",
    "    def filter_top(vals):\n",
    "        vals = [v.strip() for v in vals.split(sep)]\n",
    "        return [v if v in top else 'Outros' for v in vals] if outros else [v for v in vals if v in top]\n",
    "\n",
    "    train_processed = train_series.apply(filter_top)\n",
    "    test_processed = test_series.apply(filter_top)\n",
    "\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    train_encoded = pd.DataFrame(\n",
    "        mlb.fit_transform(train_processed),\n",
    "        columns=[f'{prefix}_{cls}' for cls in mlb.classes_],\n",
    "        index=train_series.index\n",
    "    )\n",
    "    test_encoded = pd.DataFrame(\n",
    "        mlb.transform(test_processed),\n",
    "        columns=[f'{prefix}_{cls}' for cls in mlb.classes_],\n",
    "        index=test_series.index\n",
    "    )\n",
    "    return train_encoded, test_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfeb4217",
   "metadata": {},
   "source": [
    "## DIVISÃO E TRANSFORMAÇÃO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cca63d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['vote_average'])\n",
    "y = df['vote_average']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "genres_train, genres_test = process_multilabel_column(\n",
    "    X_train['genres'], X_test['genres'], sep='-', top_n=12, outros=True, prefix='genre'\n",
    ")\n",
    "X_train = X_train.drop(columns='genres').join(genres_train)\n",
    "X_test = X_test.drop(columns='genres').join(genres_test)\n",
    "\n",
    "production_train, production_test = process_multilabel_column(\n",
    "    X_train['production_companies'], X_test['production_companies'], sep='-', top_n=10, outros=True, prefix='production'\n",
    ")\n",
    "X_train = X_train.drop(columns='production_companies').join(production_train)\n",
    "X_test = X_test.drop(columns='production_companies').join(production_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5db7c8",
   "metadata": {},
   "source": [
    "# Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ec3b0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = ['popularity', 'budget', 'runtime']\n",
    "categorical_col = ['original_language']\n",
    "date_column = 'release_date'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab27cef",
   "metadata": {},
   "source": [
    "### Pré-processamento completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9d01324",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline([\n",
    "    ('logcap', LogCapTransformer(columns=numerical_cols)),\n",
    "    ('scale', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipeline, numerical_cols),\n",
    "    ('cat', cat_pipeline, categorical_col)\n",
    "], remainder='passthrough')\n",
    "\n",
    "full_pipeline = Pipeline([\n",
    "    ('date', DateFeatureExtractor(date_column=date_column)),\n",
    "    ('preprocess', preprocessor)\n",
    "])\n",
    "\n",
    "X_train_transf = full_pipeline.fit_transform(X_train)\n",
    "X_test_transf = full_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1785d76e",
   "metadata": {},
   "source": [
    "### Aplicando SMOGN, SMOTE e SMOTEENN\n",
    "- Balanceamento para usar SMOTE e SMOTEENN na regressão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a66712f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dist_matrix: 100%|##########| 706/706 [01:52<00:00,  6.27it/s]\n",
      "synth_matrix: 100%|##########| 706/706 [00:01<00:00, 386.31it/s]\n",
      "r_index: 100%|##########| 353/353 [00:00<00:00, 658.62it/s]\n",
      "dist_matrix: 100%|##########| 542/542 [01:23<00:00,  6.51it/s]\n",
      "synth_matrix: 100%|##########| 542/542 [00:02<00:00, 215.28it/s]\n",
      "r_index: 100%|##########| 303/303 [00:00<00:00, 639.20it/s]\n"
     ]
    }
   ],
   "source": [
    "# Transformar alvo contínuo em bins\n",
    "y_train_binned = pd.qcut(y_train, q=5, labels=False)\n",
    "\n",
    "# SMOTE\n",
    "X_smote, y_smote = SMOTE(random_state=42).fit_resample(X_train_transf, y_train_binned)\n",
    "\n",
    "# SMOTEENN\n",
    "X_smoteenn, y_smoteenn = SMOTEENN(random_state=42).fit_resample(X_train_transf, y_train_binned)\n",
    "\n",
    "# SMOGN\n",
    "X_smogn_df = pd.DataFrame(X_train_transf)\n",
    "X_smogn_df['vote_average'] = y_train.values\n",
    "X_smogn = smogn.smoter(data=X_smogn_df, y='vote_average', k=3, samp_method='balance')\n",
    "y_smogn = X_smogn['vote_average']\n",
    "X_smogn = X_smogn.drop(columns=['vote_average'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b78457c",
   "metadata": {},
   "source": [
    "# Treinamento dos Modelos\n",
    "- Modelo XGBRegressor\n",
    "- Modelo SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c00c529",
   "metadata": {},
   "source": [
    "### XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4e14a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "Melhores parâmetros XGB: {'regressor__colsample_bytree': 0.8508037069686584, 'regressor__learning_rate': 0.025443625374996805, 'regressor__max_depth': 7, 'regressor__n_estimators': 228, 'regressor__subsample': 0.7718685672000917}\n",
      "Melhor R² (XGB): 0.48698226649020937\n"
     ]
    }
   ],
   "source": [
    "xgb_pipeline = Pipeline([\n",
    "    ('regressor', XGBRegressor(objective='reg:squarederror', random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "param_dist_xgb = {\n",
    "    'regressor__n_estimators': randint(100, 300),\n",
    "    'regressor__max_depth': randint(3, 10),\n",
    "    'regressor__learning_rate': uniform(0.01, 0.3),\n",
    "    'regressor__subsample': uniform(0.7, 0.3),\n",
    "    'regressor__colsample_bytree': uniform(0.7, 0.3),\n",
    "}\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "xgb_rand = RandomizedSearchCV(\n",
    "    estimator=xgb_pipeline,\n",
    "    param_distributions=param_dist_xgb,\n",
    "    n_iter=60,\n",
    "    cv=kf,\n",
    "    scoring='r2',\n",
    "    random_state=42,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "xgb_rand.fit(X_train_transf, y_train)\n",
    "print(\"Melhores parâmetros XGB:\", xgb_rand.best_params_)\n",
    "print(\"Melhor R² (XGB):\", xgb_rand.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f303d7c0",
   "metadata": {},
   "source": [
    "### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc4b7744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Melhores parâmetros SVR: {'regressor__C': 0.017073967431528128, 'regressor__epsilon': 0.26985284373248053, 'regressor__gamma': 'auto', 'regressor__kernel': 'linear'}\n",
      "Melhor R² (SVR): 0.4141686272365884\n"
     ]
    }
   ],
   "source": [
    "svr_pipeline = Pipeline([\n",
    "    ('regressor', SVR())\n",
    "])\n",
    "\n",
    "param_dist_svr = {\n",
    "    'regressor__kernel': ['rbf', 'linear'],\n",
    "    'regressor__C': loguniform(1e-2, 1e2),\n",
    "    'regressor__epsilon': uniform(0.01, 0.3),\n",
    "    'regressor__gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "svm_rand = RandomizedSearchCV(\n",
    "    estimator=svr_pipeline,\n",
    "    param_distributions=param_dist_svr,\n",
    "    n_iter=10,\n",
    "    cv=kf,\n",
    "    scoring='r2',\n",
    "    random_state=42,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "svm_rand.fit(X_train_transf, y_train)\n",
    "print(\"Melhores parâmetros SVR:\", svm_rand.best_params_)\n",
    "print(\"Melhor R² (SVR):\", svm_rand.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5cef16",
   "metadata": {},
   "source": [
    "# Avaliação final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3eb016d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "def strip_regressor_prefix(params):\n",
    "    return {k.replace('regressor__', ''): v for k, v in params.items()}\n",
    "\n",
    "xgb_best_params = strip_regressor_prefix(xgb_rand.best_params_)\n",
    "svr_best_params = strip_regressor_prefix(svm_rand.best_params_)\n",
    "\n",
    "modelos_bal = {\n",
    "    'XGBRegressor + SMOTE': XGBRegressor(**xgb_best_params, objective='reg:squarederror', n_jobs=-1),\n",
    "    'XGBRegressor + SMOTEENN': XGBRegressor(**xgb_best_params, objective='reg:squarederror', n_jobs=-1),\n",
    "    'XGBRegressor + SMOGN': XGBRegressor(**xgb_best_params, objective='reg:squarederror', n_jobs=-1),\n",
    "    'SVR + SMOTE': SVR(**svr_best_params),\n",
    "    'SVR + SMOTEENN': SVR(**svr_best_params),\n",
    "    'SVR + SMOGN': SVR(**svr_best_params),\n",
    "}\n",
    "\n",
    "resultados2 = []\n",
    "\n",
    "for nome, modelo in modelos_bal.items():\n",
    "    if 'SMOGN' in nome:\n",
    "        X_bal, y_bal = X_smogn, y_smogn\n",
    "    elif 'SMOTEENN' in nome:\n",
    "        X_bal, y_bal = X_smoteenn, y_smoteenn\n",
    "    else:\n",
    "        X_bal, y_bal = X_smote, y_smote\n",
    "\n",
    "    modelo.fit(X_bal, y_bal)\n",
    "    y_pred = modelo.predict(X_test_transf)\n",
    "\n",
    "    resultados2.append({\n",
    "        'Modelo': nome,\n",
    "        'MSE': mean_squared_error(y_test, y_pred),\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_test, y_pred)),\n",
    "        'R²': r2_score(y_test, y_pred)\n",
    "    })\n",
    "\n",
    "resultados_df2 = pd.DataFrame(resultados2)\n",
    "print(resultados_df2.sort_values(by='R²', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f9d900",
   "metadata": {},
   "source": [
    "```markdown\n",
    "Modelo                      |     MSE     |   RMSE   |     R²\n",
    "---------------------------|-------------|----------|-----------\n",
    "XGBRegressor + SMOGN       |   0.467544  | 0.683772 |  0.417634\n",
    "SVR + SMOGN                |   0.625158  | 0.790670 |  0.221312\n",
    "XGBRegressor + SMOTEENN    |  19.161391  | 4.377373 | -22.867152\n",
    "SVR + SMOTEENN             |  19.654185  | 4.433304 | -23.480970\n",
    "SVR + SMOTE                |  19.829205  | 4.453000 | -23.698972\n",
    "XGBRegressor + SMOTE       |  19.904447  | 4.461440 | -23.792692\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa56258a",
   "metadata": {},
   "source": [
    "## Testes com modelos de tratamento de outliers diferentes (Com SMOGN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a4b6bcff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dist_matrix: 100%|##########| 706/706 [01:51<00:00,  6.34it/s]\n",
      "synth_matrix: 100%|##########| 706/706 [00:01<00:00, 383.56it/s]\n",
      "r_index: 100%|##########| 353/353 [00:00<00:00, 775.77it/s]\n",
      "dist_matrix: 100%|##########| 542/542 [01:23<00:00,  6.45it/s]\n",
      "synth_matrix: 100%|##########| 542/542 [00:02<00:00, 207.48it/s]\n",
      "r_index: 100%|##########| 303/303 [00:00<00:00, 602.69it/s]\n",
      "dist_matrix: 100%|##########| 706/706 [02:03<00:00,  5.74it/s]\n",
      "synth_matrix: 100%|##########| 706/706 [00:03<00:00, 198.57it/s]\n",
      "r_index: 100%|##########| 353/353 [00:00<00:00, 397.85it/s]\n",
      "dist_matrix: 100%|##########| 542/542 [01:25<00:00,  6.36it/s]\n",
      "synth_matrix: 100%|##########| 542/542 [00:02<00:00, 213.38it/s]\n",
      "r_index: 100%|##########| 303/303 [00:00<00:00, 621.87it/s]\n",
      "dist_matrix: 100%|##########| 706/706 [02:12<00:00,  5.33it/s]\n",
      "synth_matrix: 100%|##########| 706/706 [00:01<00:00, 380.92it/s]\n",
      "r_index: 100%|##########| 353/353 [00:00<00:00, 746.50it/s]\n",
      "dist_matrix: 100%|##########| 542/542 [01:22<00:00,  6.56it/s]\n",
      "synth_matrix: 100%|##########| 542/542 [00:02<00:00, 211.18it/s]\n",
      "r_index: 100%|##########| 303/303 [00:00<00:00, 635.55it/s]\n",
      "dist_matrix: 100%|##########| 706/706 [01:52<00:00,  6.30it/s]\n",
      "synth_matrix: 100%|##########| 706/706 [00:03<00:00, 211.26it/s]\n",
      "r_index: 100%|##########| 353/353 [00:00<00:00, 390.15it/s]\n",
      "dist_matrix: 100%|##########| 542/542 [02:12<00:00,  4.08it/s]\n",
      "synth_matrix: 100%|##########| 542/542 [00:02<00:00, 211.65it/s]\n",
      "r_index: 100%|##########| 303/303 [00:00<00:00, 621.88it/s]\n",
      "dist_matrix: 100%|##########| 706/706 [01:51<00:00,  6.33it/s]\n",
      "synth_matrix: 100%|##########| 706/706 [00:01<00:00, 373.09it/s]\n",
      "r_index: 100%|##########| 353/353 [00:00<00:00, 743.59it/s]\n",
      "dist_matrix: 100%|##########| 542/542 [01:27<00:00,  6.21it/s]\n",
      "synth_matrix: 100%|##########| 542/542 [00:02<00:00, 214.82it/s]\n",
      "r_index: 100%|##########| 303/303 [00:00<00:00, 639.22it/s]\n",
      "dist_matrix: 100%|##########| 706/706 [01:49<00:00,  6.43it/s]\n",
      "synth_matrix: 100%|##########| 706/706 [00:01<00:00, 383.07it/s]\n",
      "r_index: 100%|##########| 353/353 [00:00<00:00, 768.13it/s]\n",
      "dist_matrix: 100%|##########| 542/542 [01:21<00:00,  6.67it/s]\n",
      "synth_matrix: 100%|##########| 542/542 [00:02<00:00, 213.35it/s]\n",
      "r_index: 100%|##########| 303/303 [00:00<00:00, 632.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Transformação       MSE      RMSE        R²\n",
      "1      Standard  0.434842  0.659426  0.482482\n",
      "4      Quantile  0.439627  0.663044  0.476788\n",
      "3    YeoJohnson  0.441031  0.664101  0.475117\n",
      "5       CapOnly  0.442977  0.665565  0.472801\n",
      "2        Robust  0.446271  0.668035  0.468880\n",
      "0        LogCap  0.447623  0.669046  0.467272\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "def strip_regressor_prefix(params):\n",
    "    return {k.replace('regressor__', ''): v for k, v in params.items()}\n",
    "\n",
    "xgb_best_params = strip_regressor_prefix(xgb_rand.best_params_)\n",
    "svr_best_params = strip_regressor_prefix(svm_rand.best_params_)\n",
    "\n",
    "pipelines_num = {\n",
    "    'LogCap': Pipeline([('logcap', LogCapTransformer(columns=numerical_cols)), ('scale', StandardScaler())]),\n",
    "    'Standard': Pipeline([('scale', StandardScaler())]),\n",
    "    'Robust': Pipeline([('scale', RobustScaler())]),\n",
    "    'YeoJohnson': Pipeline([('power', PowerTransformer(method='yeo-johnson')), ('scale', StandardScaler())]),\n",
    "    'Quantile': Pipeline([('quantile', QuantileTransformer(output_distribution='normal')), ('scale', StandardScaler())]),\n",
    "    'CapOnly': Pipeline([('cap', CapTransformer(columns=numerical_cols)), ('scale', StandardScaler())])\n",
    "}\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for nome_transf, pipeline_num in pipelines_num.items():\n",
    "    # Reconstroi o preprocessor com essa transformação\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', pipeline_num, numerical_cols),\n",
    "        ('cat', cat_pipeline, categorical_col)\n",
    "    ], remainder='passthrough')\n",
    "\n",
    "    full_pipeline = Pipeline([\n",
    "        ('date', DateFeatureExtractor(date_column=date_column)),\n",
    "        ('preprocess', preprocessor)\n",
    "    ])\n",
    "\n",
    "    X_train_transf = full_pipeline.fit_transform(X_train)\n",
    "    X_test_transf = full_pipeline.transform(X_test)\n",
    "\n",
    "    # Aplique SMOGN aqui (ou SMOTE/SMOTEENN, se quiser variar também)\n",
    "    X_smogn_df = pd.DataFrame(X_train_transf)\n",
    "    X_smogn_df['vote_average'] = y_train.values\n",
    "    X_smogn = smogn.smoter(data=X_smogn_df, y='vote_average', k=3, samp_method='balance')\n",
    "    y_smogn = X_smogn['vote_average']\n",
    "    X_smogn = X_smogn.drop(columns=['vote_average'])\n",
    "\n",
    "    modelo = XGBRegressor(**xgb_best_params, objective='reg:squarederror', n_jobs=-1)\n",
    "    modelo.fit(X_smogn, y_smogn)\n",
    "    y_pred = modelo.predict(X_test_transf)\n",
    "\n",
    "    resultados.append({\n",
    "        'Transformação': nome_transf,\n",
    "        'MSE': mean_squared_error(y_test, y_pred),\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_test, y_pred)),\n",
    "        'R²': r2_score(y_test, y_pred)\n",
    "    })\n",
    "\n",
    "df_resultados = pd.DataFrame(resultados).sort_values(by='R²', ascending=False)\n",
    "print(df_resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052739fc",
   "metadata": {},
   "source": [
    "## Testes com modelos de tratamento de outliers diferentes (Sem SMOGN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe2ac9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Transformação       MSE      RMSE        R²\n",
      "1      Standard  0.414784  0.644037  0.506354\n",
      "2        Robust  0.414784  0.644037  0.506354\n",
      "3    YeoJohnson  0.414784  0.644037  0.506354\n",
      "4      Quantile  0.414784  0.644037  0.506354\n",
      "0        LogCap  0.417818  0.646389  0.502743\n",
      "5       CapOnly  0.417818  0.646389  0.502743\n"
     ]
    }
   ],
   "source": [
    "def strip_regressor_prefix(params):\n",
    "    return {k.replace('regressor__', ''): v for k, v in params.items()}\n",
    "\n",
    "xgb_best_params = strip_regressor_prefix(xgb_rand.best_params_)\n",
    "\n",
    "resultados1 = []\n",
    "\n",
    "pipelines_num = {\n",
    "    'LogCap': Pipeline([('logcap', LogCapTransformer(columns=numerical_cols)), ('scale', StandardScaler())]),\n",
    "    'Standard': Pipeline([('scale', StandardScaler())]),\n",
    "    'Robust': Pipeline([('scale', RobustScaler())]),\n",
    "    'YeoJohnson': Pipeline([('power', PowerTransformer(method='yeo-johnson')), ('scale', StandardScaler())]),\n",
    "    'Quantile': Pipeline([('quantile', QuantileTransformer(output_distribution='normal')), ('scale', StandardScaler())]),\n",
    "    'CapOnly': Pipeline([('cap', CapTransformer(columns=numerical_cols)), ('scale', StandardScaler())])\n",
    "}\n",
    "\n",
    "for nome_transf, pipeline_num in pipelines_num.items():\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', pipeline_num, numerical_cols),\n",
    "        ('cat', cat_pipeline, categorical_col)\n",
    "    ], remainder='passthrough')\n",
    "\n",
    "    full_pipeline = Pipeline([\n",
    "        ('date', DateFeatureExtractor(date_column=date_column)),\n",
    "        ('preprocess', preprocessor)\n",
    "    ])\n",
    "\n",
    "    X_train_transf = full_pipeline.fit_transform(X_train)\n",
    "    X_test_transf = full_pipeline.transform(X_test)\n",
    "\n",
    "    modelo = XGBRegressor(**xgb_best_params, objective='reg:squarederror', n_jobs=-1)\n",
    "    modelo.fit(X_train_transf, y_train)\n",
    "    y_pred = modelo.predict(X_test_transf)\n",
    "\n",
    "    resultados1.append({\n",
    "        'Transformação': nome_transf,\n",
    "        'MSE': mean_squared_error(y_test, y_pred),\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_test, y_pred)),\n",
    "        'R²': r2_score(y_test, y_pred)\n",
    "    })\n",
    "\n",
    "df_resultados1 = pd.DataFrame(resultados1).sort_values(by='R²', ascending=False)\n",
    "print(df_resultados1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
